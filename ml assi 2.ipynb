{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b13807-8f63-4b7e-aca7-a369b1d81db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bfb538-b616-4b98-b592-34079d4c3bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Overfitting: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and irrelevant details in the data rather than the underlying patterns. The consequence of overfitting is that the model performs well on the training data but poorly on unseen or test data.\\nUnderfitting: Underfitting happens when a model is too simple to capture the underlying patterns in the data. It fails to learn the training data effectively and, as a result, performs poorly on both the training data and unseen data.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Overfitting: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and irrelevant details in the data rather than the underlying patterns. The consequence of overfitting is that the model performs well on the training data but poorly on unseen or test data.\n",
    "Underfitting: Underfitting happens when a model is too simple to capture the underlying patterns in the data. It fails to learn the training data effectively and, as a result, performs poorly on both the training data and unseen data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da5b510-6023-48da-b968-49d5ac44a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157aaaac-d0ee-4a9b-8598-de0eb4901125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use simpler models.\\nIncrease the size of your training dataset.\\nApply regularization techniques (e.g., L1 or L2 regularization).\\nUse cross-validation to assess model performance.\\nFeature engineering to reduce noise.\\nEarly stopping during training.\\nUse ensemble methods like Random Forest or Gradient Boosting.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Use simpler models.\n",
    "Increase the size of your training dataset.\n",
    "Apply regularization techniques (e.g., L1 or L2 regularization).\n",
    "Use cross-validation to assess model performance.\n",
    "Feature engineering to reduce noise.\n",
    "Early stopping during training.\n",
    "Use ensemble methods like Random Forest or Gradient Boosting.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed692df-9f6c-42b9-8c9d-001353324056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4a718c-3b07-43d3-9fe5-a880a77a44c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUnderfitting occurs when a model is too simple to capture the underlying patterns in the data. Scenarios where underfitting can occur in machine learning include:\\nUsing a linear model for a highly nonlinear problem.\\nUsing too few features to represent complex data.\\nHaving insufficient training data for the chosen model.\\nApplying overly aggressive regularization, making the model too simple.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Underfitting occurs when a model is too simple to capture the underlying patterns in the data. Scenarios where underfitting can occur in machine learning include:\n",
    "Using a linear model for a highly nonlinear problem.\n",
    "Using too few features to represent complex data.\n",
    "Having insufficient training data for the chosen model.\n",
    "Applying overly aggressive regularization, making the model too simple.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ad21401-fe00-4be4-aab1-5b1619fab2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "421fc53c-f2f2-4422-9334-cc94cb746542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bias: Bias represents the error introduced by approximating a real-world problem, which may be complex, by a simplified model. High bias models underfit the data.\\nVariance: Variance represents the error introduced by the model's sensitivity to the specific training data. High variance models overfit the data.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"bias: Bias represents the error introduced by approximating a real-world problem, which may be complex, by a simplified model. High bias models underfit the data.\n",
    "Variance: Variance represents the error introduced by the model's sensitivity to the specific training data. High variance models overfit the data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c631d6a-f22f-4cea-83e9-04c1365645cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# question5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c83941c5-d98b-4b99-80ff-00141279c616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Examining learning curves: Plotting training and validation performance over time.\\nCross-validation: Assessing model performance on different subsets of the data.\\nVisual inspection: Plotting the predicted vs. actual values.\\nMonitoring loss functions: Tracking training and validation loss during training.\\nUsing evaluation metrics: Comparing metrics like accuracy, precision, recall, and F1-score on training and validation data.\\nTo determine whether your model is overfitting or underfitting, you should observe the model's performance on both the training and validation datasets. Overfitting typically shows excellent training performance but poor validation performance, while underfitting results in poor performance on both.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Examining learning curves: Plotting training and validation performance over time.\n",
    "Cross-validation: Assessing model performance on different subsets of the data.\n",
    "Visual inspection: Plotting the predicted vs. actual values.\n",
    "Monitoring loss functions: Tracking training and validation loss during training.\n",
    "Using evaluation metrics: Comparing metrics like accuracy, precision, recall, and F1-score on training and validation data.\n",
    "To determine whether your model is overfitting or underfitting, you should observe the model's performance on both the training and validation datasets. Overfitting typically shows excellent training performance but poor validation performance, while underfitting results in poor performance on both.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "952c7426-f251-42cf-b621-413ec815a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9b07ff-c940-4676-ae5a-5faea0960503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'High Bias (Underfitting): A model with high bias is too simple to capture the underlying patterns in the data. It performs poorly on both the training and validation/test data.\\nHigh Variance (Overfitting): A model with high variance is too complex and captures noise in the training data. It performs well on the training data but poorly on the validation/test data.\\nExamples of high bias models include linear regression on a nonlinear dataset, while high variance models may include deep neural networks with too many layers for a small dataset.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"High Bias (Underfitting): A model with high bias is too simple to capture the underlying patterns in the data. It performs poorly on both the training and validation/test data.\n",
    "High Variance (Overfitting): A model with high variance is too complex and captures noise in the training data. It performs well on the training data but poorly on the validation/test data.\n",
    "Examples of high bias models include linear regression on a nonlinear dataset, while high variance models may include deep neural networks with too many layers for a small dataset.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90d77510-0a0d-4d78-8d32-53492ce0b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c76a853-9dfe-4bdd-92fa-4a275339063d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Regularization in machine learning is a technique used to prevent overfitting by adding a penalty term to the model's loss function. It encourages the model to have smaller coefficients or simpler representations. Common regularization techniques include:\\n\\nL1 Regularization (Lasso): Adds the absolute values of coefficients to the loss function. It encourages sparsity by making some coefficients exactly zero.\\nL2 Regularization (Ridge): Adds the squared values of coefficients to the loss function. It discourages large coefficients and smooths the model.\\nDropout (for neural networks): Randomly deactivates neurons during training to prevent reliance on specific neurons.\\nEarly Stopping: Monitoring the validation loss during training and stopping when it starts increasing.\\nCross-validation: Helps select hyperparameters that balance model complexity and performance.\\nRegularization techniques control model complexity, helping to find a better balance between bias and variance, ultimately improving model generalization.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Regularization in machine learning is a technique used to prevent overfitting by adding a penalty term to the model's loss function. It encourages the model to have smaller coefficients or simpler representations. Common regularization techniques include:\n",
    "\n",
    "L1 Regularization (Lasso): Adds the absolute values of coefficients to the loss function. It encourages sparsity by making some coefficients exactly zero.\n",
    "L2 Regularization (Ridge): Adds the squared values of coefficients to the loss function. It discourages large coefficients and smooths the model.\n",
    "Dropout (for neural networks): Randomly deactivates neurons during training to prevent reliance on specific neurons.\n",
    "Early Stopping: Monitoring the validation loss during training and stopping when it starts increasing.\n",
    "Cross-validation: Helps select hyperparameters that balance model complexity and performance.\n",
    "Regularization techniques control model complexity, helping to find a better balance between bias and variance, ultimately improving model generalization.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d5d7d-9111-498c-85ff-4303c55261d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
